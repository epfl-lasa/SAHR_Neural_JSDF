{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"../..\") \n",
    "import kinematics.allegro_hand as allegro\n",
    "import tools.rotations as rot\n",
    "from nn_model import Net, loss_SCA, DataLoaderX\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "hand = allegro.Robot(use_fingers=[1,1,1,1], path_prefix='../../', all_link_fk=True, meshes=True)\n",
    "lb = hand.joint_lb\n",
    "ub = hand.joint_ub\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "hand_joint_bound = np.concatenate([lb.reshape(1,-1), ub.reshape(1,-1)], axis=0)\n",
    "hand_joint_bound"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "np.savetxt('models/hand_joint_bound.txt', hand_joint_bound, delimiter=' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "hand_joint_bounds = np.loadtxt('models/hand_joint_bound.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "hand_joint_bounds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# load data\n",
    "path = '../dataset/'\n",
    "dataset_name = 'dataset'  \n",
    "nums = 10000000\n",
    "suffix = '_15dis_sphere_2'\n",
    "# dataset_name = 'test100000.txt'  # 59min 100k nums\n",
    "# data2 = np.loadtxt(path+dataset_name, delimiter=' ')  # \n",
    "data2 = np.load(path + dataset_name + str(nums) + suffix + '.npy')   #  # 16 joints, 3 obj pose, 15 min_dis\n",
    "print('data2 shape:', data2.shape)\n",
    "nums = 1000000\n",
    "data2 = data2[:nums,:]\n",
    "\n",
    "\n",
    "dis_with_obj = list(np.array([5,9,12,14,15]) + 18)\n",
    "dis_with_obj +=[16,17,18]\n",
    "# dis_with_obj\n",
    "dis_only_hand = []\n",
    "for i in range(34):\n",
    "    if i not in dis_with_obj:\n",
    "        dis_only_hand.append(i)\n",
    "print(dis_only_hand)\n",
    "data1 = data2[:, dis_only_hand] # 16 joints, 10 min_dis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "print('nonzero:',np.count_nonzero(np.min(data1[:, 16:], axis=1 ))/nums)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "max_dis = [np.max(data1[:, i] ) for i in range(16,26)]\n",
    "max_dis = np.asarray(max_dis)\n",
    "max_dis_ = np.max(max_dis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "min_dis = np.min(max_dis)\n",
    "min_dis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# normalize data to [-1,1]\n",
    "\n",
    "data = np.copy(data1)\n",
    "for i in range(16):  # joint angles\n",
    "    data[:,i] = (data2[:,i] - lb[i] )/ (ub[i] - lb[i]) *2 -1\n",
    "\n",
    "data_dis = data1[:,16:]/max_dis  # normalize for each dis of 10 \n",
    "data_dis[data_dis==0] = -1\n",
    "\n",
    "data[:, 16:] = data_dis\n",
    "\n",
    "\n",
    "\n",
    "add_sin_cos = True\n",
    "keep_all_dis = True\n",
    "\n",
    "num = int(data.shape[0] * 0.8)\n",
    "batch_size = 128 * 64 \n",
    "\n",
    "\n",
    "if add_sin_cos:\n",
    "    num_s = 16 * 3\n",
    "    if keep_all_dis:\n",
    "        data = np.concatenate([data[:,:16], np.sin(data[:,:16]), np.cos(data[:,:16]), data[:,16:]], axis=1)\n",
    "    else:\n",
    "        min_dis = np.min(data1[:, 16:], axis=1 ).reshape(-1, 1)\n",
    "        data = np.concatenate([data[:,:16], np.sin(data[:,:16]), np.cos(data[:,:16]), min_dis], axis=1)\n",
    "else:\n",
    "    num_s = 16\n",
    "    if keep_all_dis is False:\n",
    "        min_dis = np.min(data1[:, 16:], axis=1 ).reshape(-1, 1)\n",
    "        data = np.concatenate([data[:,:16], min_dis], axis=1)\n",
    "\n",
    "\n",
    "x_train = torch.Tensor(data[:num, :num_s])\n",
    "y_train = torch.Tensor(data[:num, num_s:])\n",
    "dim_in = x_train.size(1)\n",
    "dim_out = y_train.size(1)\n",
    "dataset_train = TensorDataset(x_train,y_train) # create your datset\n",
    "loader_train = DataLoaderX(dataset_train,batch_size=batch_size, num_workers=16, pin_memory=True,prefetch_factor=4, persistent_workers=True)\n",
    "x_test = torch.Tensor(data[num:, :num_s])\n",
    "y_test = torch.Tensor(data[num:, num_s:])\n",
    "\n",
    "print(dim_in, dim_out)\n",
    "del data2\n",
    "del data1\n",
    "del data_dis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "data[:num, :num_s].nbytes/1024/1024 # MB for memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "print(sys.getsizeof(torch.FloatTensor([0.5])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# sys.getsizeof(x_train)\n",
    "sys.getsizeof(x_train.storage())/1024/1024 # MB for memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "use_cuda = True\n",
    "device = torch.device(\"cuda:0\" if use_cuda else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "nums = 10000000\n",
    "suffix = '_15dis_sphere_2'\n",
    "use_cuda = True\n",
    "net = Net(suffix, nums, use_cuda=True, batch_size=20000)\n",
    "net.to(net.device)\n",
    "\n",
    "\n",
    "print(net)\n",
    "params = list(net.parameters())\n",
    "# print(params)\n",
    "print(len(params))\n",
    "# print(params[0].size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# def weights_init(m):                                               \n",
    "#     nn.init.normal_(m.weight.data, 0.0, 0.02) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# for m in net.children():\n",
    "#     if isinstance(m, nn.Linear):\n",
    "#         nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
    "#         nn.init.constant_(m.bias, 0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# for i in net.parameters():\n",
    "#     print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "weight_p, bias_p = [],[]\n",
    "for name, p in net.named_parameters():\n",
    "    if 'bias' in name:\n",
    "        bias_p += [p]\n",
    "    else:\n",
    "        weight_p += [p]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from IPython.display import clear_output\n",
    "# %% Loss fcn\n",
    "import torch.optim as optim\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "# optimizer = optim.SGD(net.parameters(),lr=0.01)\n",
    "# optimizer = optim.Adam(net.parameters(),lr=0.01,weight_decay=0.001)\n",
    "optimizer = optim.SGD([\n",
    "          {'params': weight_p, 'weight_decay':1e-5},\n",
    "          {'params': bias_p, 'weight_decay':0}\n",
    "          ], lr=15e-2, momentum=0.9)\n",
    "\n",
    "\n",
    "# net.to(device)\n",
    "\n",
    "\n",
    "t_all = []\n",
    "error_all = []\n",
    "\n",
    "t_start = time.time()\n",
    "i = 0\n",
    "while True:\n",
    "    t0 = time.time()\n",
    "    \n",
    "    for batch_idx, (x, y) in enumerate(net.loader_train):\n",
    "        optimizer.zero_grad() # zero the parameter gradients    \n",
    "        if use_cuda:\n",
    "            x = x.cuda()\n",
    "            y = y.cuda()\n",
    "        \n",
    "        # forward + backward + optimize\n",
    "        outputs = net(x)\n",
    "        loss = loss_SCA(outputs, y) #y[0,0,2,3] out[0,-0.1,3,4]\n",
    "        # loss= criterion(outputs, y)\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()   \n",
    "    \n",
    "    # del x\n",
    "    # del y\n",
    "    # error_all.append(np.sqrt(loss.data.item())*max_dis_)\n",
    "    if(i%5==0):\n",
    "        if i%50==0:\n",
    "            clear_output(wait=True)\n",
    "        print(i,\"%0.4f\"%(time.time() - t0), np.sqrt(loss.data.item()) * net.max_dis_ )\n",
    "    \n",
    "    t1 = time.time() - t0\n",
    "    t_all.append(t1)\n",
    "    i +=1\n",
    "    # if time.time() - t_start>3600*4:\n",
    "    #     break\n",
    "    if i>100:\n",
    "        break\n",
    "t_all = np.asarray(t_all)\n",
    "print('each step', np.mean(t_all))  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "net.validate(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.random.randint(0,100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "np.sqrt(loss.data.item())  * max_dis "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "net.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "max_dis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "net.x_test_gpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# verification\n",
    "\n",
    "\n",
    "with torch.no_grad():\n",
    "    outputs = net(net.x_test_gpu)\n",
    "\n",
    "outputs = outputs.cpu().numpy()\n",
    "\n",
    "outputs\n",
    "# error = (data[num:, num_s:] - outputs)\n",
    "# np.sqrt(np.mean(error*error))  * max_dis\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# in training dataset\n",
    "x_test_1 = x_test.to(device)\n",
    "y_test_1 = y_test.to(device)\n",
    "net.to(device)\n",
    "\n",
    "with torch.no_grad():\n",
    "    outputs = net(x_gpu)\n",
    "\n",
    "outputs = outputs.cpu().numpy()\n",
    "\n",
    "error = (data[:num, num_s:] - outputs)\n",
    "np.sqrt(np.mean(error*error)) * max_dis\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# save the model\n",
    "filepath = 'models/linear4_tanh_4_4hours'\n",
    "torch.save(net.state_dict(), filepath)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "a09e9255d0a6845c5a7cead237f5e158458708f4ef5283729ba0c2bf01b62a76"
  },
  "kernelspec": {
   "display_name": "Python 3.7.13 ('mujoco_sim')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}